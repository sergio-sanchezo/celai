{"config":{"lang":["en"],"separator":"[\\s\\-]+","pipeline":["stopWordFilter"]},"docs":[{"location":"","title":"Introduction","text":""},{"location":"#welcome-to-celai","title":"Welcome to Cel.ai","text":"<p>Cel.ai is a powerful Python framework designed to accelerate the development of omnichannel virtual assistants. Whether you need to integrate with platforms like WhatsApp, Telegram, or VoIP services such as VAPI.com, Cel.ai provides the tools and flexibility to get your assistant up and running quickly.</p>"},{"location":"#why-celai","title":"Why Cel.ai?","text":"<ul> <li>Rapid Development: Quickly deploy AI assistants across multiple messaging platforms.</li> <li>Flexibility: Easily create custom connectors, middlewares and assistants.</li> <li>Extensibility: Use middlewares to add custom functionality, decode messages, handle security, and session management.</li> </ul> <p>Explore the documentation to learn more about how Cel.ai can help you build powerful, omnichannel virtual assistants with ease. Feel free to customize this introduction to better fit your specific needs and use cases.</p>"},{"location":"#key-features","title":"Key Features","text":"<ul> <li>Modular Design: Designed with a modular architecture that allows you to easily extend and customize its functionality.</li> <li>Asynchronous: Built on top of the FastAPI framework, Cel.ai is designed to be asynchronous and scalable.</li> <li>Streaming: Supports different stream modes to optimize the user experience based on the specific requirements of the platform and the nature of the interaction. </li> <li>Runs on Script: This system is designed with the principle that it can run a minimal QA/FAQ + RAG assistant in a single script without requiring databases, external services, or complex configurations.</li> <li>Open Source: Cel.ai is open source and actively maintained by the community.</li> </ul>"},{"location":"#overview","title":"Overview","text":""},{"location":"#key-components","title":"Key Components","text":""},{"location":"#connectors","title":"Connectors","text":"<p>Cel.ai comes with out-of-the-box support for several popular platforms:</p> <ul> <li>WhatsApp</li> <li>Telegram</li> <li>VAPI.com</li> <li>CLI</li> </ul> <p>These connectors translate messages between the platform and Cel.ai's agnostic message format, allowing the assistant to interact with different messaging platforms seamlessly.  Additionally, the framework allows for the creation of custom connectors, enabling seamless integration with virtually any platform.</p>"},{"location":"#middlewares","title":"Middlewares","text":"<p>Cel.ai supports the use of middlewares to extend and customize the functionality of your virtual assistants. This allows for greater flexibility and control over how your assistant processes and responds to user interactions. Middlewares can be used to add custom logic, perform data validation, or perform authentication, rate limiting, blacklisting, and more.</p> <p>You will find useful middlewares for decoding messages into a suitable format for Natural Language Processing (NLP) models. Take a look of <code>GeodecodingMiddleware</code> which decodes a message shared location into a human-readable address using the Google Maps API. </p> <p>So you can easily create your own middleware to add custom functionality to your assistant. For example, you can create a <code>PDFDecodingMiddleware</code> to decode a PDF file shared by the user into a text format that can be processed by the assistant.</p>"},{"location":"#assistants","title":"Assistants","text":"<p>At the core of Cel.ai are Assistants, which handle everything from conversation history persistence to state management and Retrieval-Augmented Generation (RAG). The framework includes a built-in assistant named Macaw, which is implemented using LangChain. However, you can also create your own assistant using the framework or any LLM model of your choice.</p>"},{"location":"getting_started/","title":"Getting Started","text":"<p>Welcome to the Cel.ai documentation! This guide will help you get started with creating your first omnichannel virtual assistant using the Cel.ai framework.</p>"},{"location":"getting_started/#prerequisites","title":"Prerequisites","text":"<p>Before you begin, ensure you have the following installed:</p> <ul> <li>Python 3.11 or higher</li> <li>pip (Python package installer)</li> </ul>"},{"location":"getting_started/#installation","title":"Installation","text":"<p>To install Cel.ai, you can use pip. Run the following command in your terminal:</p> <pre><code>pip install celai\n</code></pre>"},{"location":"getting_started/#creating-your-first-assistant","title":"Creating Your First Assistant","text":"<p>Follow these steps to create your first virtual assistant with Cel.ai.</p>"},{"location":"getting_started/#step-1-initialize-your-project","title":"Step 1: Initialize Your Project","text":"<p>Create a new directory for your project and navigate into it:</p> <pre><code>mkdir my_celai_assistant\ncd my_celai_assistant\n</code></pre>"},{"location":"getting_started/#step-2-create-a-virtual-environment","title":"Step 2: Create a Virtual Environment","text":"<p>It's a good practice to use a virtual environment for your project. Run the following commands to create and activate a virtual environment:</p> <pre><code>python -m venv venv\nsource venv/bin/activate  # On Windows use `venv\\Scripts\\activate`\n</code></pre>"},{"location":"getting_started/#step-3-install-celai","title":"Step 3: Install Cel.ai","text":"<p>With your virtual environment activated, install Cel.ai:</p> <pre><code>pip install celai\n</code></pre>"},{"location":"getting_started/#step-4-create-your-assistant-script","title":"Step 4: Create Your Assistant Script","text":"<p>If you are using Macaw Assistant, you need to add a environment variable <code>OPENAI_API_KEY</code> with your OpenAI API key.</p> <pre><code>export OPENAI_API_KEY=\"your_openai_api_key\"\n</code></pre> <p>For simplicity, we will create a basic assistant that uses the CLI connector to interact with the assistant via the command line interface. Create a new Python file, <code>assistant.py</code>, and open it in your favorite text editor. Add the following code to set up a basic assistant:</p> main.py<pre><code># Import Cel.ai modules\nfrom cel.connectors.cli.cli_connector import CliConnector\nfrom cel.gateway.message_gateway import MessageGateway, StreamMode\nfrom cel.message_enhancers.smart_message_enhancer_openai import SmartMessageEnhancerOpenAI\nfrom cel.assistants.macaw.macaw_assistant import MacawAssistant\nfrom cel.prompt.prompt_template import PromptTemplate\n\n# Setup prompt\nprompt = \"\"\"You are an AI assistant. Called Celia. You can help a user to buy Bitcoins.\"\"\"\nprompt_template = PromptTemplate(prompt)\n\n# Create the assistant based on the Macaw Assistant \nast = MacawAssistant(\n    prompt=prompt_template\n)\n\n# Create the Message Gateway - This component is the core of the assistant\n# It handles the communication between the assistant and the connectors\ngateway = MessageGateway(ast)\n\n# For this example, we will use the Telegram connector\nconn = CliConnector(\n    stream_mode=StreamMode.FULL\n)\n# Register the connector with the gateway\ngateway.register_connector(conn)\n\n# Then start the gateway and begin processing messages\ngateway.run()\n</code></pre>"},{"location":"getting_started/#step-5-run-your-assistant","title":"Step 5: Run Your Assistant","text":"<p>Save your <code>main.py</code> file and run it using the following command:</p> <pre><code>python main.py\n</code></pre> <p>Then you can interact with your assistant through the command line interface. Just type your message and press Enter to send it to the assistant.</p>"},{"location":"connectors/","title":"Introduction","text":"<p>Welcome to the Cel.ai Connectors documentation. This page provides an overview of the connectors supported by Cel.ai and instructions on how to create custom connectors.</p>"},{"location":"connectors/#what-are-connectors","title":"What Are Connectors?","text":"<p>Cel.ai is a Python framework designed to accelerate the development of omnichannel virtual assistants.  Connectors in Cel.ai are responsible for translating back and forth between the platform-specific message format and Cel.ai's agnostic message format. So connectors are a decpoupling layer between the messaging platform and Cel.ai's message format.</p> <p>Each connector is responsible for handling the specifics of a particular messaging platform, and register in Message Gateway the required endpoints to receive messages from the platform.</p>"},{"location":"connectors/#webhook-overview","title":"Webhook Overview","text":"<p>Message Gateway is the core component of Cel.ai that handles the communication between the assistant and the connectors. It is responsible for processing incoming messages, invoking the assistant, and sending responses back to the connectors.</p> <p>Message Gateway runs a single FastAPI server that listens for incoming messages for all registered connectors. When a connector registers into the gateway, it provides the routes that the gateway should listen to for incoming messages.</p> <p> </p> <p>So in order to receive messages from a messaging platform, you need a public URL that the platform can send messages to. This is where a webhook comes into play. Usually messaging platforms require a public HTTPS endpoint to send messages to your assistant.</p> <p>You can use tools like ngrok to create a secure tunnel to your local server, providing a public URL that can be used to receive webhooks and other HTTP requests from external services. Take a look at the Webhook URL with ngrok guide to learn how to set up ngrok and expose your local server to the internet securely.</p> <p>Some users have reported that they have been able to use pinggy.io to create a public URL for their local server. You can try it out and see if it works for you.</p> Whatsapp and ngrok <p>Whatsapp may not work with ngrok free tier. Today 24 June 2024 only works with ngrok paid tier.</p>"},{"location":"connectors/#supported-connectors","title":"Supported Connectors","text":"<p>Cel.ai comes with out-of-the-box support for the following connectors:</p> <ul> <li>WhatsApp</li> <li>Telegram</li> <li>VAPI.com</li> <li>CLI</li> </ul>"},{"location":"connectors/stream_mode/","title":"Stream Modes","text":"<p>Cel.ai supports different stream modes to define how the client, through the connector, receives responses from the AI assistant. These modes are designed to optimize the user experience based on the specific requirements of the platform and the nature of the interaction. Below are the available stream modes:</p> <p> </p>"},{"location":"connectors/stream_mode/#stream-modes_1","title":"Stream Modes","text":""},{"location":"connectors/stream_mode/#1-direct","title":"1. DIRECT","text":"<p>In the DIRECT mode, each chunk of text generated by the LLM (Large Language Model) is immediately sent to the connector. This mode is ideal for scenarios where real-time response generation is crucial, such as in Text-to-Speech (TTS) applications.</p> <ul> <li>Use Case: Real-time TTS generation.</li> <li>Behavior: Sends each chunk of text as soon as it is generated by the LLM.</li> <li>Advantages: Immediate feedback, suitable for real-time applications.</li> </ul>"},{"location":"connectors/stream_mode/#2-sentence","title":"2. SENTENCE","text":"<p>The SENTENCE mode allows the construction of paragraphs or sentences before sending them to the connector. This mode is particularly useful for messaging platforms where responses can be lengthy. It enables the user to start receiving parts of the response without waiting for the entire response to be generated by the LLM, thus improving response times and user experience.</p> <ul> <li>Use Case: Messaging platforms with potentially lengthy responses.</li> <li>Behavior: Sends paragraphs or sentences as they are constructed.</li> <li>Advantages: Improved response times, better user experience for lengthy messages.</li> </ul>"},{"location":"connectors/stream_mode/#3-full","title":"3. FULL","text":"<p>In the FULL mode, the response is sent to the connector only after the LLM has completed the entire inference process. This mode is ideal for use with Message Enhancers, where the complete response needs to be processed or enhanced before being delivered to the user.</p> <ul> <li>Use Case: Scenarios requiring complete response processing, such as with Message Enhancers.</li> <li>Behavior: Sends the complete response after the LLM has finished generating it.</li> <li>Advantages: Ensures the response is fully processed or enhanced before delivery.</li> </ul>"},{"location":"connectors/stream_mode/#summary","title":"Summary","text":"Stream Mode Use Case Behavior Advantages DIRECT Real-time TTS generation Sends each chunk of text immediately Immediate feedback, real-time applications SENTENCE Messaging platforms with lengthy responses Sends paragraphs or sentences as they are constructed Improved response times, better UX for lengthy messages FULL Scenarios requiring complete response processing Sends the complete response after full generation Ensures fully processed or enhanced responses <p>By selecting the appropriate stream mode, developers can tailor the behavior of their AI assistants to best fit the needs of their specific application and platform, ensuring optimal performance and user satisfaction.</p>"},{"location":"connectors/webhook_url/","title":"Webhook URL with ngrok","text":""},{"location":"connectors/webhook_url/#introduction","title":"Introduction","text":"<p>Ngrok is a tool that allows you to expose a local server to the internet securely. It creates a secure tunnel to your localhost, providing a public URL that can be used to receive webhooks and other HTTP requests from external services. This is particularly useful for developing and testing integrations with platforms like WhatsApp and Telegram, which require a publicly accessible HTTPS endpoint to send messages and updates.</p>"},{"location":"connectors/webhook_url/#why-use-ngrok","title":"Why Use ngrok?","text":"<ul> <li>Secure Tunneling: Ngrok provides a secure tunnel to your local server, ensuring that your data is encrypted.</li> <li>Public URL: It generates a public URL that can be accessed from anywhere, making it easy to test webhooks and other integrations.</li> <li>Ease of Use: Setting up ngrok is straightforward and requires minimal configuration.</li> </ul>"},{"location":"connectors/webhook_url/#steps-to-set-up-ngrok","title":"Steps to Set Up ngrok","text":""},{"location":"connectors/webhook_url/#step-1-download-and-install-ngrok","title":"Step 1: Download and Install ngrok","text":"<p>Visit the ngrok website and download the appropriate version for your operating system.</p>"},{"location":"connectors/webhook_url/#step-2-sign-up-and-authenticate","title":"Step 2: Sign Up and Authenticate","text":"<ol> <li>Sign up for a free account on the ngrok website.</li> <li>After signing up, you will receive an authentication token.</li> <li> <p>Open a terminal and run the following command to authenticate ngrok with your account:</p> <pre><code>ngrok authtoken YOUR_AUTH_TOKEN\n</code></pre> <p>Replace <code>YOUR_AUTH_TOKEN</code> with the token you received.</p> </li> </ol>"},{"location":"connectors/webhook_url/#step-3-start-ngrok","title":"Step 3: Start ngrok","text":"<ol> <li>Open a terminal.</li> <li> <p>Run the following command to start ngrok and create a tunnel to your local server:</p> <pre><code>ngrok http 5004\n</code></pre> </li> <li> <p>You will see output similar to the following:</p> <pre><code>ngrok by @inconshreveable                                                                                                      (Ctrl+C to quit)\n\nSession Status                online\nAccount                       Your Name (Plan: Free)\nVersion                       2.3.35\nRegion                        United States (us)\nWeb Interface                 http://127.0.0.1:4040\nForwarding                    http://abcd1234.ngrok.io -&gt; http://127.0.0.1:5004\nForwarding                    https://abcd1234.ngrok.io -&gt; http://127.0.0.1:5004\n\nConnections                   ttl     opn     rt1     rt5     p50     p90\n                              0       0       0.00    0.00    0.00    0.00\n</code></pre> </li> <li> <p>Note the <code>https://abcd1234.ngrok.io</code> URL. This is the public HTTPS URL that forwards requests to your local server running on <code>127.0.0.1:5004</code>.</p> </li> </ol>"},{"location":"connectors/webhook_url/#step-4-use-the-public-url","title":"Step 4: Use the Public URL","text":"<ul> <li>Use the <code>https://abcd1234.ngrok.io/whatsapp</code> URL to configure webhooks or other integrations with platforms like WhatsApp.</li> <li>Use <code>https://abcd1234.ngrok.io/telegram</code> for Telegram integrations.</li> <li>Ensure that your Cel.ai Assistant is running on local server <code>127.0.0.1:5004</code>.</li> </ul>"},{"location":"connectors/webhook_url/#conclusion","title":"Conclusion","text":"<p>By following these steps, you have successfully set up ngrok to create a secure tunnel to your local server. You now have a public HTTPS URL that can be used to receive messages and updates from platforms like WhatsApp and Telegram. This setup is ideal for development and testing purposes, allowing you to work with webhooks and other integrations seamlessly.</p>"},{"location":"connectors/whatsapp/","title":"WhatsApp Connector","text":"<p>The <code>Whatsapp Connector</code> is a component of the Cel.ai framework that allows seamless integration with the WhatsApp Cloud API. This connector translates messages between WhatsApp and Cel.ai's agnostic message format, enabling the development of virtual assistants that can interact with users on WhatsApp.</p>"},{"location":"connectors/whatsapp/#initialization","title":"Initialization","text":"<p>To initialize the <code>Whatsapp Connector</code>, you need to provide the Meta Access Token, Phone Number ID, and a verification token. Optionally, you can also specify an endpoint prefix and stream mode.</p>"},{"location":"connectors/whatsapp/#parameters","title":"Parameters","text":"<ul> <li><code>token</code> (str): The Meta Access Token. This is required.</li> <li><code>phone_number_id</code> (str): The Meta Phone Number ID. This is required.</li> <li><code>verify_token</code> (str): The verification token used for webhook verification. This is required.</li> <li><code>endpoint_prefix</code> (str, optional): The prefix for the webhook endpoint. Defaults to <code>\"/whatsapp\"</code>.</li> <li><code>stream_mode</code> (StreamMode, optional): The mode for streaming messages. Defaults to <code>StreamMode.SENTENCE</code>. See Stream Modes for more information.</li> </ul>"},{"location":"connectors/whatsapp/#example","title":"Example","text":"<pre><code>from cel.connectors.whatsapp.whatsapp_connector import WhatsappConnector\n\nwsp = WhatsappConnector(token=os.getenv(\"WHATSAPP_TOKEN\"), \n                    phone_number_id=os.getenv(\"WHATSAPP_PHONE_NUMBER_ID\"),\n                    verify_token=\"123456\",\n                    endpoint_prefix=\"/whatsapp\",\n                    stream_mode=StreamMode.FULL)\n</code></pre>"},{"location":"connectors/whatsapp/#attributes","title":"Attributes","text":"<ul> <li><code>token</code> (str): The Meta Access Token.</li> <li><code>phone_number_id</code> (str): The Meta Phone Number ID.</li> <li><code>base_url</code> (str): The base URL for the WhatsApp Cloud API.</li> <li><code>url</code> (str): The full URL for sending messages.</li> <li><code>verify_token</code> (str): The verification token. Setup this token in the WhatsApp Cloud API settings.</li> <li><code>endpoint_prefix</code> (str): The prefix for the webhook endpoint.</li> <li><code>stream_mode</code> (StreamMode): The mode for streaming messages.</li> <li><code>verification_handler</code> (callable): The handler for verification requests.</li> </ul>"},{"location":"connectors/whatsapp/#whatsapp-assistant","title":"Whatsapp Assistant","text":"main.py<pre><code># Import Cel.ai modules\nfrom cel.gateway.message_gateway import MessageGateway, StreamMode\nfrom cel.message_enhancers.smart_message_enhancer_openai import SmartMessageEnhancerOpenAI\nfrom cel.assistants.macaw.macaw_assistant import MacawAssistant\nfrom cel.prompt.prompt_template import PromptTemplate\nfrom cel.connectors.whatsapp.whatsapp_connector import WhatsappConnector\n\n\n# Setup prompt\nprompt = \"\"\"You are an AI assistant. Called Celia. You can help a user to buy Bitcoins.\"\"\"\nprompt_template = PromptTemplate(prompt)\n\n# Create the assistant based on the Macaw Assistant \nast = MacawAssistant(\n    prompt=prompt_template\n)\n\n# Create the Message Gateway - This component is the core of the assistant\n# It handles the communication between the assistant and the connectors\ngateway = MessageGateway(\n    webhook_url=os.environ.get(\"WEBHOOK_URL\"),\n    assistant=ast,\n    host=\"127.0.0.1\", port=5004,\n    message_enhancer=SmartMessageEnhancerOpenAI(),\n    delivery_rate_control=False\n)\n\nwsp = WhatsappConnector(token=os.getenv(\"WHATSAPP_TOKEN\"), \n                    phone_number_id=os.getenv(\"WHATSAPP_PHONE_NUMBER_ID\"),\n                    verify_token=\"123456\",\n                    stream_mode=StreamMode.FULL)\n\n# Register the connector with the gateway\ngateway.register_connector(wsp)\n\n# Then start the gateway and begin processing messages\ngateway.run()\n</code></pre>"},{"location":"connectors/whatsapp/#notes","title":"Notes","text":"<ul> <li>Ensure that the <code>WHATSAPP_TOKEN</code> Meta Access Token and <code>WHATSAPP_PHONE_NUMBER_ID</code> Phone Number ID are valid and have the necessary permissions to interact with the WhatsApp Cloud API.</li> <li>Get the <code>WHATSAPP_TOKEN</code> and <code>WHATSAPP_PHONE_NUMBER_ID</code> from the WhatsApp Business API settings.</li> <li>The verification token is used to verify the webhook endpoint with WhatsApp. Make sure it matches the token you set in the WhatsApp Cloud API settings.</li> </ul> <p>This documentation provides an overview of the <code>WhatsappConnector</code> and how to initialize and use it within the Cel.ai framework. For more detailed information, refer to the Cel.ai official documentation.</p>"}]}